---
title: "Pstat231HW4"
author: "Wentao Yu"
date: '2022-11-01'
output: html_document
---
```{r include=FALSE}
library(tidymodels)
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(corrr)
library(discrim)
library(poissonreg)
library(klaR)
library(pROC)
tidymodels_prefer()
```
## Question 1
```{r split data}
df <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/HWs/homework-3/data/titanic.csv') %>%
  mutate(survived = factor(survived, 
                           levels = c("Yes", "No")),
         pclass = factor(pclass))
set.seed(891) # keep the outcome stable
titanic_split <- initial_split(df, prop = 0.80, strata = survived) # split the data and stratified on survived
titanic_training <- training(titanic_split) # extract the training data
titanic_testing <- testing(titanic_split) # extract the testing data
```

## Question 2
```{r k-fold CV}
titanic_fold <- vfold_cv(titanic_training, v=10)
titanic_fold
```

## Question 3
If we want to use the entire data set, we can use leave-one-out cross validation. 

## Question 4
```{r dummy recipe}
titanic_recipe <- recipe(survived ~ pclass+sex+age+sib_sp+parch+fare, data = titanic_training) %>%
  step_impute_linear(age) %>%
  step_dummy(all_nominal_predictors()) %>% 
  step_interact(terms = ~ starts_with('sex'):fare+
                  age:fare)
summary(titanic_recipe)
```
```{r engine & workflow}
log_reg <- logistic_reg() %>% 
  set_engine('glm') %>% 
  set_mode('classification')
log_wf <- workflow() %>% 
  add_model(log_reg) %>% 
  add_recipe(titanic_recipe)
#log_fit <- fit(log_wf, titanic_training)
```
```{r LDA}
lda_mode <- discrim_linear() %>% 
  set_engine('MASS') %>% 
  set_mode('classification')
lda_wf <- workflow() %>% 
  add_model(lda_mode) %>% 
  add_recipe(titanic_recipe)
#lda_fit <- fit(lda_wf, titanic_training)
```
```{r QDA}
qda_mode <- discrim_quad() %>% 
  set_engine('MASS') %>% 
  set_mode('classification')
qda_wf <- workflow() %>% 
  add_model(qda_mode) %>% 
  add_recipe(titanic_recipe)
#qda_fit <- fit(qda_wf, titanic_training)
```

## Question 5
```{r logistic fit}
log_fit <- fit_resamples(log_wf, titanic_fold)
```
```{r lda}
lda_fit <- fit_resamples(lda_wf, titanic_fold)
```
```{r qda}
qda_fit <- fit_resamples(qda_wf, titanic_fold)
```

## Question 6
```{r}
mx1 <- collect_metrics(log_fit)
mx1
mx2 <- collect_metrics(lda_fit)
mx2
mx3 <- collect_metrics(qda_fit)
mx3
results <- bind_rows(mx1, mx2, mx3) %>%
  tibble() %>% mutate(model = rep(c("Logistic Regression", "Linear Discrminant Analysis", "Quadratic Discrminant Analysis"), each = 2)) %>%
  dplyr::select(model, .metric, mean, std_err)
results
```
logistic regression seems to be the best model. 

## Question 7
```{r}
log_new_fit <- fit(log_wf, titanic_training)
```

## Question 8
```{r}
log_acc <- predict(log_new_fit, new_data = titanic_testing, type = 'class') %>% 
  bind_cols(titanic_testing %>% select(survived)) %>% 
  accuracy(truth = survived, estimate = .pred_class)
log_acc
```

## Pstat231 Only
$Y = \beta X+\epsilon$

## Questin 9
$$
\left(\begin{array}{c}
y_1\\
y_2\\
\cdot\\
\cdot\\
\cdot\\
y_n
\end{array} \right)=
\left(\begin{array}{c}
x_{11}&x_{12}&\cdot&\cdot&\cdot&x_{1n}\\
x_{21}&x_{22}&\cdot&\cdot&\cdot&x_{2n}\\
\cdot&\cdot&\cdot&\cdot&\cdot&\cdot\\
\cdot&\cdot&\cdot&\cdot&\cdot&\cdot\\
\cdot&\cdot&\cdot&\cdot&\cdot&\cdot\\
x_{n1}&x_{n2}&\cdot&\cdot&\cdot&x_{nn}\\
\end{array}\right)
\left(\begin{array}{c}
\beta_1\\
\beta_2\\
\cdot\\
\cdot\\
\cdot\\
\beta_n
\end{array} \right)+
\left(\begin{array}{c}
\epsilon_1\\
\epsilon_2\\
\cdot\\
\cdot\\
\cdot\\
\epsilon_n
\end{array} \right)
$$
Least square estimator -> min$\epsilon'\epsilon = (y-X\beta)'(y-X\beta) = y'y-2\beta'X'y+\beta'X'X\beta$\
$\frac{\partial\epsilon'\epsilon}{\partial\beta} = -2X'y+2X'Xb = 0$\
$X'X\beta = X'y$\
$\beta = (X'X)^{-1}X'y$

## Questin 10
$$\begin{equation*}
\begin{split}
Cov(\hat{\beta_1}, \hat{\beta_2}) 
  &=(X^TX)^{-1}X^T(\sigma^2 I)((X^TX)^{-1}X^T)^T\\
  &=\sigma^2(X^TX)^{-1}X^T((X^TX)^{-1}X^T)^T\\
  &=\sigma^2(X^TX)^{-1}X^TX(X^TX)^{-1}\\
  &=\sigma^2(X^TX)^{-1}
\end{split}
\end{equation*}
$$









