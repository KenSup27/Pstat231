pokemon_forest_model <- rand_forest(mtry = tune(), trees = tune(), min_n = tune()) %>%
set_engine('ranger', importance = "impurity") %>%
set_mode('classification')
pokemon_forest_wkflow <- workflow() %>%
add_model(pokemon_forest_model) %>%
add_recipe(pokemon.recipe)
param1_grid <- grid_regular(mtry(range = c(1,8)), trees(range = c(200,400)), min_n(range = c(2,8)), levels = 8)
tune_forest <- tune_grid(
pokemon_forest_wkflow,
resamples = pokemon.fold,
grid = param1_grid,
metrics = metric_set(roc_auc)
)
autoplot(tune_forest)
collect_metrics(tune_forest)
best_model2 <- select_best(tune_forest, metric = 'roc_auc')
pokemon_forest_best <- finalize_workflow(pokemon_forest_wkflow, best_model2)
pokemon_forest_best_fit <- fit(pokemon_forest_best, data = pokemon.training)
random_forest <- augment(pokemon_forest_best_fit, pokemon.training, type = 'prob') %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water)
random_forest
extract_fit_engine(pokemon_forest_best_fit) %>%
vip()
pokemon_boost_model <- boost_tree(trees = tune()) %>%
set_engine("xgboost") %>%
set_mode("classification")
pokemon_boost_wkflow <- workflow() %>%
add_model(pokemon_boost_model) %>%
add_recipe(pokemon.recipe)
param2_grid <- grid_regular(trees(range(c(10,2000))), levels = 10)
tune_boost <- tune_grid(
pokemon_boost_wkflow,
resamples = pokemon.fold,
grid = param2_grid,
metrics = metric_set(roc_auc)
)
autoplot(tune_boost)
collect_metrics(tune_boost)
best_model3 <- select_best(tune_boost, metric = 'roc_auc')
pokemon_boost_best <- finalize_workflow(pokemon_boost_wkflow, best_model3)
pokemon_boost_best_fit <- fit(pokemon_boost_best, data = pokemon.training)
boosted_tree <- augment(pokemon_boost_best_fit, pokemon.training, type = 'prob') %>%
roc_auc(truth=type_1, estimate = .pred_Bug:.pred_Water)
boosted_tree
bind_rows(pruned_tree, random_forest, boosted_tree) %>%
tibble() %>%
mutate(model = c('pruned tree model', 'random forest model', 'boost tree model'), .before = .metric)
# Boost Tree model is the best one.
#pokemon_boost_tree_testing <- fit(pokemon_boost_best, data = pokemon.testing) %>%
augment(pokemon_boost_best_fit, pokemon.testing, type = 'prob') %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water)
abalone <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/HWs/homework-6/data/abalone.csv')
age <- abalone[9]+1.5 # extract the rings column since age = rings+1.5
abalone2 <- cbind(abalone,age) # add a new column into the dataframe
names(abalone2)[10] <- 'age' # rename the new column as age
abalone2_split <- initial_split(abalone2, prop = 0.8, strata = age)
abalone_training <- training(abalone2_split)
abalone_testing <- testing(abalone2_split)
abalone_fold <- vfold_cv(abalone_training, v = 5, strata = age)  #cross validation
abalone_recipe <- recipe(age~., data = abalone_training) %>%
step_dummy(all_nominal_predictors()) %>%
step_interact(terms = ~ shucked_weight:starts_with('type')+
diameter:longest_shell+
shell_weight:shucked_weight) %>%
step_center(all_predictors()) %>%
step_scale(all_predictors())
abalone_rand_forest <- rand_forest(mtry = tune(), trees = tune(), min_n = tune()) %>%
set_engine('ranger') %>%
set_mode('regression')
abalone_wkflow <- workflow() %>%
add_model(abalone_rand_forest) %>%
add_recipe(abalone_recipe)
forest_tune <- grid_regular(mtry(range = c(1,8)), trees(range = c(200,400)), min_n(range = c(2,8)), levels = 10)
abalone_tune_forest <- tune_grid(
abalone_wkflow,
resamples = abalone_fold,
grid = forest_tune,
metrics = metric_set(rmse)
)
autoplot(abalone_tune_forest)
collect_metrics(abalone_tune_forest)
abalone_best_model <- select_best(abalone_tune_forest, metric = 'rmse')
abalone_finalwkflow <- finalize_workflow(abalone_wkflow, abalone_best_model)
abalone_best_fit <- fit(abalone_finalwkflow, data = abalone_training) %>%
augment(abalone_testing, type = 'class') %>%
rmse(truth = age, estimate = .pred)
abalone_best_fit
abalone_training
ï¼Ÿmetric_set()
?metric_set
bind_rows(pruned_tree, random_forest, boosted_tree) %>%
tibble() %>%
mutate(model = c('pruned tree model', 'random forest model', 'boost tree model'), .before = .metric)
library(xgboost)
library(vip)
library(ranger)
library(rpart.plot)
library(corrplot)
library(tidymodels)
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(corrr)
library(discrim)
library(poissonreg)
library(klaR)
library(pROC)
library(janitor)
library(glmnet)
library(ISLR)
library(ISLR2)
tidymodels_prefer()
bind_rows(pruned_tree, random_forest, boosted_tree) %>%
tibble() %>%
mutate(model = c('pruned tree model', 'random forest model', 'boost tree model'), .before = .metric)
# Boost Tree model is the best one.
#pokemon_boost_tree_testing <- fit(pokemon_boost_best, data = pokemon.testing) %>%
augment(pokemon_forest_best_fit, pokemon.testing, type = 'prob') %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water)
waterdata <- read.csv(.\water_probability.csv)
waterdata <- read.csv(.\Final Project\water_probability.csv)
waterdata <- read.csv(.\ Final Project\water_probability.csv)
getwd()
waterdata <- read.csv(Final Project\water_probability.csv)
waterdata <- read.csv(\Final Project\water_probability.csv)
waterdata <- read.csv(/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/Pstat131/Final Project/water_probability.csv)
waterdata <- read.csv(/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/Pstat131/Final Project/water_probability.csv)
waterdata <- read.csv(\Users\wentaoyu\Documents\UCSB File\Stats\Pstat131\Pstat131\Final Project\water_probability.csv)
library(xts)
library(quantmod)
library(ggplot2)
library(tidymodels)
library(tidyverse)
tidymodels_prefer()
waterdata <- read.csv(.\Final Project\water_probability.csv)
waterdata <- read.csv(\Users\wentaoyu\Documents\UCSB File\Stats\Pstat131\Pstat131\Final Project\water_probability.csv)
waterdata <- read.csv('.\Final Project\water_probability.csv')
waterdata <- read.csv('\Users\wentaoyu\Documents\UCSB File\Stats\Pstat131\Pstat131\Final Project\water_probability.csv')
waterdata <- read.csv('./Final Project/water_probability.csv')
waterdata <- read.csv('./Final Project/water_probability.csv')
waterdata <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/Pstat131/Final Project/water_probability.csv')
waterdata <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/Pstat131/Final Project/water_probability.csv')
waterdata <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/Pstat131/Final Project/water_probability.csv')
waterdata <- read.csv('./Final Project/water_probability.csv')
waterdata <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/Pstat131/Final Project/water_probability.csv')
waterdata <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/Pstat131/Final Project/water_probability.csv')
setwd('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/Pstat131')
waterdata <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/Pstat131/Final Project/water_probability.csv')
waterdata <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/Pstat131/Final Project/water_probability.csv')
waterdata <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/Pstat131/Final Project/water_protability.csv')
waterdata <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/Pstat131/Final Project/water_potability.csv')
waterdata <- read.csv('./Final Project/water_potability.csv')
waterdata <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/Pstat131/Final Project/water_potability.csv')
library(xts)
library(quantmod)
library(ggplot2)
library(tidymodels)
library(tidyverse)
tidymodels_prefer()
waterdata <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/Pstat131/Final Project/water_potability.csv')
waterdata <- clean_names(waterdata)
library(xgboost)
library(vip)
library(ranger)
library(rpart.plot)
library(corrplot)
library(tidymodels)
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(corrr)
library(discrim)
library(poissonreg)
library(klaR)
library(pROC)
library(janitor)
library(glmnet)
library(ISLR)
library(ISLR2)
tidymodels_prefer()
waterdata <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/Pstat131/Final Project/water_potability.csv')
waterdata <- clean_names(waterdata)
waterdata <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/Pstat131/Final Project/water_potability.csv')
waterdata <- clean_names(waterdata)
waterdata
waterdata <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/Pstat131/Final Project/water_potability.csv')
waterdata <- clean_names(waterdata)
dim(waterdata)
library(xgboost)
library(vip)
library(ranger)
library(rpart.plot)
library(corrplot)
library(tidymodels)
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(corrr)
library(discrim)
library(poissonreg)
library(klaR)
library(pROC)
library(janitor)
library(glmnet)
library(ISLR)
library(ISLR2)
tidymodels_prefer()
waterdata
waterdata <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/Pstat131/Final Project/water_potability.csv')
waterdata <- clean_names(waterdata)
dim(waterdata)
waterdata <- mutate(waterdata, potability =
factor(potability, levels = c(1,0)))
waterdata
corr(waterdata)
cor_water <- waterdata %>%
select(-potability)
cor_water <- waterdata %>%
select(-potability) %>%
correlate()
cor_water
cor_water <- waterdata %>%
select(-potability) %>%
correlate()
rplot(cor_water)
cor_water <- waterdata %>%
select(-potability) %>%
correlate(use = complete.obs, method = pearson)
cor_water <- waterdata %>%
select(-potability) %>%
correlate(use = 'complete.obs', method = 'pearson')
rplot(cor_water)
cor_water <- waterdata %>%
select(-potability) %>%
cor(use = 'complete.obs', method = 'pearson')
corrplot(cor_water, method = 'number', type = 'lower')
library(xgboost)
library(vip)
library(ranger)
library(rpart.plot)
library(corrplot)
library(tidymodels)
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(corrr)
library(discrim)
library(poissonreg)
library(klaR)
library(pROC)
library(janitor)
library(glmnet)
library(ISLR)
library(ISLR2)
tidymodels_prefer()
install.packages(c("bit", "bslib", "callr", "data.table", "dials", "evaluate", "forecast", "fracdiff", "future", "future.apply", "ggplot2", "ggrepel", "globals", "ISLR2", "knitr", "lubridate", "markdown", "Matrix", "modelr", "parsnip", "pkgload", "plyr", "processx", "ps", "R.utils", "rbibutils", "RcppArmadillo", "recipes", "rmarkdown", "roxygen2", "sass", "shiny", "slider", "styler", "vctrs", "workflows", "xfun", "zip"))
install.packages(c("bit", "bslib", "callr", "data.table", "dials", "evaluate", "forecast", "fracdiff", "future", "future.apply", "ggplot2", "ggrepel", "globals", "ISLR2", "knitr", "lubridate", "markdown", "Matrix", "modelr", "parsnip", "pkgload", "plyr", "processx", "ps", "R.utils", "rbibutils", "RcppArmadillo", "recipes", "rmarkdown", "roxygen2", "sass", "shiny", "slider", "styler", "vctrs", "workflows", "xfun", "zip"))
install.packages(c("bit", "bslib", "callr", "data.table", "dials", "evaluate", "forecast", "fracdiff", "future", "future.apply", "ggplot2", "ggrepel", "globals", "ISLR2", "knitr", "lubridate", "markdown", "Matrix", "modelr", "parsnip", "pkgload", "plyr", "processx", "ps", "R.utils", "rbibutils", "RcppArmadillo", "recipes", "rmarkdown", "roxygen2", "sass", "shiny", "slider", "styler", "vctrs", "workflows", "xfun", "zip"))
install.packages('compiler')
knitr::opts_chunk$set(cache = TRUE)
library(compiler)
library(xgboost)
library(vip)
library(ranger)
library(rpart.plot)
library(corrplot)
library(tidymodels)
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(corrr)
library(discrim)
library(poissonreg)
library(klaR)
library(pROC)
library(janitor)
library(glmnet)
library(ISLR)
library(ISLR2)
tidymodels_prefer()
waterdata <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/Pstat131/Final Project/water_potability.csv')
waterdata <- clean_names(waterdata)
dim(waterdata)
waterdata <- waterdata %>% na_kalman() %>%
mutate(waterdata, potability =
factor(potability, levels = c(1,0))) # make sure that 1 represents success.
waterdata <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/Pstat131/Final Project/water_potability.csv')
waterdata <- clean_names(waterdata)
dim(waterdata)
waterdata <- mutate(waterdata, potability =
factor(potability, levels = c(1,0))) # make sure that 1 represents success.
waterdata <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/Pstat131/Final Project/water_potability.csv')
waterdata <- clean_names(waterdata)
dim(waterdata)
waterdata <- mutate(waterdata, potability =
factor(potability, levels = c(1,0))) # make sure that 1 represents success.
waterdata <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/Pstat131/Final Project/water_potability.csv')
waterdata <- clean_names(waterdata)
waterdata <- mutate(waterdata, potability =
factor(potability, levels = c(1,0))) # make sure that 1 represents success.
waterdata <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/Pstat131/Final Project/water_potability.csv')
waterdata <- clean_names(waterdata)
waterdata <- mutate(waterdata, potability =
factor(potability, levels = c(1,0))) # make sure that 1 represents success.
ggplot(waterdata, aes(potability))+
geom_bar()
cor_water <- waterdata %>%
select(-potability) %>%
cor(use = 'complete.obs', method = 'pearson')
corrplot(cor_water, method = 'number', type = 'lower') # draw the correlation plot
set.seed(3276)
water.split <- initial_split(waterdata, prop = 0.8, strata = potability)
water_training <- training(water.split)
water_testing <- testing(water.split)
water_fold <- vfold_cv(water_training, v = 10, strata = potability) # cross validation
water_recipe <- recipe(potability~., data = water_training)%>% # create a recipe that used later.
step_impute_knn(all_predictors()) %>% # using the knn to impute the missing data
step_scale(all_predictors()) %>%
step_center(all_predictors())
water_recipe %>%
prep() %>%
juice()
water_log_reg <- logistic_reg() %>%
set_engine('glm') %>%
set_mode('classification') # does it have to be regression or classification?
water_log_wf <- workflow() %>%
add_model(water_log_reg) %>%
add_recipe(water_recipe)
water_log_fit <- fit(water_log_wf, water_training) # Can folded data set fit into logistic regression ?
water_boost_model <- boost_tree(trees = tune()) %>%
set_engine("xgboost") %>%
set_mode("classification")
water_boost_wkflow <- workflow() %>%
add_model(water_boost_model) %>%
add_recipe(water_recipe)
param2_grid <- grid_regular(trees(range(c(10,2000))), levels = 10)
tune_boost <- tune_grid(
water_boost_wkflow,
resamples = water_fold,
grid = param2_grid,
metrics = metric_set(roc_auc)
)
library(xgboost)
library(vip)
library(ranger)
library(rpart.plot)
library(corrplot)
library(tidymodels)
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(corrr)
library(discrim)
library(poissonreg)
library(klaR)
library(pROC)
library(janitor)
library(glmnet)
library(ISLR)
library(ISLR2)
tidymodels_prefer()
## table reading
df0 <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/HWs/homework-5/data/Pokemon.csv')
df <- clean_names(df0)
df1 <- dplyr::filter(df, type_1 %in% c('Bug','Fire','Grass','Normal','Water','Psychic')) %>%
mutate(type_1 = factor(type_1),
legendary = factor(legendary),
generation = factor(generation)) ## select the required outcomes and factor type_1, legendary, and generation.
set.seed(721) ## set seed to stabilize the outcome
pokemon.split <- initial_split(df1, prop = 0.8, strata = type_1)
pokemon.training <- training(pokemon.split)
pokemon.testing <- testing(pokemon.split)
pokemon.fold <- vfold_cv(pokemon.training, v=5, strata = type_1) ## return the distribution of strata variable to each fold.
length(pokemon.training)
dim(pokemon.training)
pokemon.recipe <- recipe(type_1 ~ legendary+generation+sp_atk+attack+speed+defense+hp+sp_def, data = pokemon.training) %>%
step_dummy(c(legendary,generation)) %>%
step_scale(all_predictors()) %>%
step_center(all_predictors())
cor.pokemon <- pokemon.training %>%
select(-c(total, name, type_1, type_2, generation, legendary)) %>%  # eliminate chr variables
correlate() # create correlation data frame
rplot(cor.pokemon) # create correlation plot
tree.pokemon <- decision_tree() %>%
set_engine('rpart') %>%
set_mode('classification')
pokemon_wkflow <- workflow() %>%
add_model(tree.pokemon %>% set_args(cost_complexity = tune())) %>%
add_recipe(pokemon.recipe)
param_grid <- grid_regular(cost_complexity(range = c(-3,-1)), levels = 10)
tune_tree <- tune_grid(
pokemon_wkflow,
resamples = pokemon.fold,
grid = param_grid,
metrics = metric_set(roc_auc)
)
autoplot(tune_tree)
collect_metrics(tune_tree)
best_model <- select_best(tune_tree, metric = 'roc_auc')
pokemon_tree_best <- finalize_workflow(pokemon_wkflow, best_model)
pokemon_tree_best_fit <- fit(pokemon_tree_best, data = pokemon.training)
pruned_tree <- augment(pokemon_tree_best_fit, pokemon.training, type = 'prob') %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water)
pruned_tree
pokemon_tree_best_fit %>%
extract_fit_engine() %>%
rpart.plot(roundint = F)
# warning ???
pokemon_forest_model <- rand_forest(mtry = tune(), trees = tune(), min_n = tune()) %>%
set_engine('ranger', importance = "impurity") %>%
set_mode('classification')
pokemon_forest_wkflow <- workflow() %>%
add_model(pokemon_forest_model) %>%
add_recipe(pokemon.recipe)
param1_grid <- grid_regular(mtry(range = c(1,8)), trees(range = c(200,400)), min_n(range = c(2,8)), levels = 8)
?write_rds
tune_forest <- tune_grid(
pokemon_forest_wkflow,
resamples = pokemon.fold,
grid = param1_grid,
metrics = metric_set(roc_auc)
)
autoplot(tune_forest)
write_rds(tune_forest, path = 'tune_forest.rds')
write_rds(tune_forest, file = 'tune_forest.rds')
collect_metrics(tune_forest)
best_model2 <- select_best(tune_forest, metric = 'roc_auc')
pokemon_forest_best <- finalize_workflow(pokemon_forest_wkflow, best_model2)
pokemon_forest_best_fit <- fit(pokemon_forest_best, data = pokemon.training)
random_forest <- augment(pokemon_forest_best_fit, pokemon.training, type = 'prob') %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water)
random_forest
extract_fit_engine(pokemon_forest_best_fit) %>%
vip()
collect_metrics(tune_forest)
best_model2 <- select_best(tune_forest, metric = 'roc_auc')
pokemon_forest_best <- finalize_workflow(pokemon_forest_wkflow, best_model2)
pokemon_forest_best_fit <- fit(pokemon_forest_best, data = pokemon.training)
random_forest <- augment(pokemon_forest_best_fit, pokemon.training, type = 'prob') %>%
roc_auc(truth = type_1, estimate = .pred_Bug:.pred_Water)
random_forest
extract_fit_engine(pokemon_forest_best_fit) %>%
vip()
pokemon_boost_model <- boost_tree(trees = tune()) %>%
set_engine("xgboost") %>%
set_mode("classification")
pokemon_boost_wkflow <- workflow() %>%
add_model(pokemon_boost_model) %>%
add_recipe(pokemon.recipe)
param2_grid <- grid_regular(trees(range(c(10,2000))), levels = 10)
tune_boost <- tune_grid(
pokemon_boost_wkflow,
resamples = pokemon.fold,
grid = param2_grid,
metrics = metric_set(roc_auc)
)
write_rds(tune_boost, file = 'tune_boost.rds')
autoplot(tune_boost)
abalone <- read.csv('/Users/wentaoyu/Documents/UCSB File/Stats/Pstat131/HWs/homework-6/data/abalone.csv')
age <- abalone[9]+1.5 # extract the rings column since age = rings+1.5
abalone2 <- cbind(abalone,age) # add a new column into the dataframe
names(abalone2)[10] <- 'age' # rename the new column as age
abalone2_split <- initial_split(abalone2, prop = 0.8, strata = age)
abalone_training <- training(abalone2_split)
abalone_testing <- testing(abalone2_split)
abalone_fold <- vfold_cv(abalone_training, v = 5, strata = age)  #cross validation
abalone_recipe <- recipe(age~., data = abalone_training) %>%
step_dummy(all_nominal_predictors()) %>%
step_interact(terms = ~ shucked_weight:starts_with('type')+
diameter:longest_shell+
shell_weight:shucked_weight) %>%
step_center(all_predictors()) %>%
step_scale(all_predictors())
abalone_rand_forest <- rand_forest(mtry = tune(), trees = tune(), min_n = tune()) %>%
set_engine('ranger') %>%
set_mode('regression')
abalone_wkflow <- workflow() %>%
add_model(abalone_rand_forest) %>%
add_recipe(abalone_recipe)
forest_tune <- grid_regular(mtry(range = c(1,8)), trees(range = c(200,400)), min_n(range = c(2,8)), levels = 10)
abalone_tune_forest <- tune_grid(
abalone_wkflow,
resamples = abalone_fold,
grid = forest_tune,
metrics = metric_set(rmse)
)
write_rds(abalone_tune_forest, file = 'abalone_tune_forest.rds')
read_rds('abalone_tune_forest.rds')
autoplot(abalone_tune_forest)
collect_metrics(abalone_tune_forest)
abalone_best_model <- select_best(abalone_tune_forest, metric = 'rmse')
abalone_finalwkflow <- finalize_workflow(abalone_wkflow, abalone_best_model)
abalone_best_fit <- fit(abalone_finalwkflow, data = abalone_training) %>%
augment(abalone_testing, type = 'class') %>%
rmse(truth = age, estimate = .pred)
abalone_best_fit
read_rds(file = 'tune_forest.rds')
write_rds(tune_forest, file = 'tune_forest.rds')
read_rds(file = 'tune_forest.rds')
autoplot(tune_forest)
#tune_forest <- tune_grid(
#  pokemon_forest_wkflow,
#  resamples = pokemon.fold,
#  grid = param1_grid,
#  metrics = metric_set(roc_auc)
#)
write_rds(tune_forest, file = 'tune_forest.rds')
read_rds(file = 'tune_forest.rds')
autoplot(tune_forest)
write_rds(tune_boost, file = 'tune_boost.rds')
read_rds('tune_boost.rds')
autoplot(tune_boost)
